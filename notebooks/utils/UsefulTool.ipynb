{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse lda Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = {\n",
    "    'Business ethics': 0,\n",
    "    'Data security': 1,\n",
    "    'Access_And_Affordability': 2,\n",
    "    'Business_Model_Resilience': 3,\n",
    "    'Competitive_Behavior': 4,\n",
    "    'Critical_Incident_Risk_Management': 5,\n",
    "    'Customer_Welfare': 6,\n",
    "    'Director_Removal': 7,\n",
    "    'Employee_Engagement_Inclusion_And_Diversity': 8,\n",
    "    'Employee_Health_And_Safety': 9,\n",
    "    'Human_Rights_And_Community_Relations': 10,\n",
    "    'Labor_Practices': 11,\n",
    "    'Management_Of_Legal_And_Regulatory_Framework': 12,\n",
    "    'Physical_Impacts_Of_Climate_Change': 13,\n",
    "    'Product_Quality_And_Safety': 14,\n",
    "    'Product_Design_And_Lifecycle_Management': 15,\n",
    "    'Selling_Practices_And_Product_Labeling': 16,\n",
    "    'Supply_Chain_Management': 17,\n",
    "    'Systemic_Risk_Management': 18,\n",
    "    'Waste_And_Hazardous_Materials_Management': 19,\n",
    "    'Water_And_Wastewater_Management': 20,\n",
    "    'Air_Quality': 21,\n",
    "    'Customer_Privacy': 22,\n",
    "    'Ecological_Impacts': 23,\n",
    "    'Energy_Management': 24,\n",
    "    'GHG_Emissions': 25,\n",
    "    'No_sufficient_information': 26\n",
    "}\n",
    "reversed_dict = {value: key for key, value in lda.items()}\n",
    "df['gpt_label'] = df['tmp'].map(reversed_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GPT3.5 label extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_map(row):\n",
    "    row = row.strip('[')\n",
    "    row = row.strip(']')\n",
    "    li = row.split(',')\n",
    "    y = []\n",
    "    try:\n",
    "        for x in li:\n",
    "            y.append(reversed_dict[int(x)])\n",
    "    except:\n",
    "        y.append('No sufficient information')\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DownSampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = df['label'].value_counts()\n",
    "cnt =0\n",
    "for i in range(27):\n",
    "    if i != 26 and i != 8 and i != 22 and i != 14 and i != 4 and i != 6 and i != 21 and i != 16:\n",
    "        cnt += tmp[i]\n",
    "print(cnt / 19)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = df.sample(frac=1, random_state=42)\n",
    "# Define the classes to downsample\n",
    "majority_classes = [26, 8, 25, 13, 3, 23, 12, 24, 10]\n",
    "\n",
    "# Calculate the downsample size as a fraction of the smallest class\n",
    "\n",
    "downsample_size = 320\n",
    "\n",
    "# Downsampling\n",
    "downsampled_data = pd.concat([\n",
    "    data[data['label'] == label].sample(downsample_size, replace=False) \n",
    "    for label in majority_classes\n",
    "])\n",
    "minority_data = data[~data['label'].isin(majority_classes)]\n",
    "balanced_data = pd.concat([downsampled_data, minority_data])\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Loss function Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('[', end='')\n",
    "for i in range(27):\n",
    "    print(tmp[i], ',', end='')\n",
    "print(']', end='')\n",
    "downsampling_size = max(x)\n",
    "frequency = [round(downsampling_size / i, 2) for i in x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert string to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Integer'].astype('int32')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seperate ChatGPT reason part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_integer = r'2\\.(.*)\\n*'\n",
    "df['Keywords'] = label.str.extract(pattern_integer)\n",
    "pattern_integer = r'3\\.(.*)'\n",
    "df['Reason'] = label.str.extract(pattern_integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r'\\d+(\\D*)\\s*(?=\\n2\\.)'\n",
    "pattern2 = r'\\d+'\n",
    "integer = ['0' for _ in range(813)]\n",
    "for i in range(len(label)):\n",
    "    match = re.search(pattern, label[i])\n",
    "    if match:\n",
    "    # Extract the matched string from group 0\n",
    "        extracted_value = match.group(0)\n",
    "        integer[i] = extracted_value\n",
    "for i in range(len(integer)):\n",
    "    match = re.search(pattern2, integer[i])\n",
    "    if match:\n",
    "    # Extract the matched string from group 0\n",
    "        extracted_value = match.group(0)\n",
    "        integer[i] = extracted_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Address the null row in pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index[df['part3'].isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "invalid_values = []\n",
    "for index, row in df1.iterrows():\n",
    "    try:\n",
    "        df1.at[index, 'label'] = int(row['label'])\n",
    "    except ValueError:\n",
    "        invalid_values.append(row['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Match string regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern_x = r'(\\d\\,\\s){26}\\d'\n",
    "filtered_df = df.loc[df['label'].str.contains(pattern_x)]\n",
    "filtered_df = df.loc[df['label'].str.match(pattern_x)]\n",
    "matches = df['label'].str.extract(pattern_x)\n",
    "matches = df['label'].str.findall(pattern_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Draw distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "value_counts = label.value_counts()\n",
    "for key, value in value_counts.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "labels = ['Label 0', 'Label 1']\n",
    "plt.pie(value_counts, labels=labels, autopct='%1.1f%%')\n",
    "plt.title('Label Distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filter rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df.loc[df['label'].str.match(r'^([0-9]|1[0-9]|2[0-6])$')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter specific row and lenght\n",
    "first = df[[i[0]!='Fail to convert' for i in df['label']]]\n",
    "first = first[[len(i.split())>10 for i in first['paragraph']]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concate df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in file_list:\n",
    "    print(file)\n",
    "    file_name = file.strip('.pdf')\n",
    "    df = pd.read_csv(f'./american/clean_predict_csv/{file_name}.csv')\n",
    "    print(len(df))\n",
    "    df1 = pd.concat([df1, df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "american_all_file = [\n",
    "'1_dow_1_85.pdf', \n",
    "'2_agilent_1_106.pdf', '3_amazon_1_79.pdf', '4_apple_1_72.pdf',\n",
    "'5_boeing_1_66.pdf', '6_bxp_1_65.pdf', '7_charles_1_50.pdf', '8_cisco_1_56.pdf', '9_citigroup_1_137.pdf', '10_cme_1_34.pdf', \n",
    "'11_colgate_1_84.pdf', '12_corning_1_71.pdf', '13_expeditor_1_37.pdf', '14_eei_1_80.pdf', '15_itt_1_44.pdf', \n",
    "'16_fedex_1_34.pdf', '17_firstscolar_1_57.pdf', '18_google_1_14.pdf', '19_intel_1_86.pdf', '20_jpmorgan_1_61.pdf', \n",
    "'21_microsoft_1_89.pdf', '22_rockwell_1_58.pdf', '23_ibm_1_49.pdf', '24_traveler_1_147.pdf', '25_visa_1_52.pdf', '0710_Tino_clean.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taiwan_all_file = [ '1_umc_1_154.pdf',\n",
    "'2_agilent_1_106.pdf', '3_amazon_1_79.pdf', '4_apple_1_72.pdf',\n",
    "'5_boeing_1_66.pdf', '6_bxp_1_65.pdf', '7_charles_1_50.pdf', '8_cisco_1_56.pdf', '9_citigroup_1_137.pdf', '10_cme_1_34.pdf', \n",
    "'11_colgate_1_84.pdf', '12_corning_1_71.pdf', '13_expeditor_1_37.pdf', '14_eei_1_80.pdf', '15_itt_1_44.pdf', \n",
    "'16_fedex_1_34.pdf', '17_firstscolar_1_57.pdf', '18_google_1_14.pdf', '19_intel_1_86.pdf', '20_jpmorgan_1_61.pdf', \n",
    "'21_microsoft_1_89.pdf', '22_rockwell_1_58.pdf', '23_ibm_1_49.pdf', '24_traveler_1_147.pdf', '25_visa_1_52.pdf']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taiwan_rest_file = ['1_umc_1_154.pdf',\n",
    " '2_tsmc_1_210.pdf', '3_macronix_1_114.pdf', '4_esun_1_154.pdf', '5_eme_1_46.pdf',\n",
    " '6_asus_1_108.pdf', '7_acer_1_127.pdf', '8_witron_1_93.pdf', '9_honhai_1_22.pdf', '10_compal_1_169.pdf',\n",
    "  '11_quanta_1_123.pdf', '12_formosa_1_18.pdf', '14_qisda_1_134.pdf', '15_msi_1_97.pdf',\n",
    " '18_novatek_1_140.pdf', '19_mediatek_1_97.pdf', \n",
    "   '21_cathay_1_52.pdf', '23_fubon_1_89.pdf', '24_mega_1_68.pdf', '25_ctbc_1_117.pdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Csv for Tino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./0710_result_for_Tino.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count frequency and weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "counts = []\n",
    "for i, row in df.iterrows():\n",
    "    x = set()\n",
    "    for label in row['label']:\n",
    "        x.add(str(label))\n",
    "        # print(label)\n",
    "        # Iterate through the rows of the CSV file\n",
    "    labels.extend(x)\n",
    "for i in range(27):\n",
    "    # count label number in collected column value\n",
    "    count = labels.count(str(i))\n",
    "    counts.append(count)\n",
    "all_counts = sum(counts)\n",
    "weights = []\n",
    "probability = []\n",
    "for index, x in enumerate(counts):\n",
    "    result = x / all_counts\n",
    "    print(f\"{index} : {result:.5f}\")\n",
    "    weight = round((1 / result) / 10, 5)\n",
    "    probability.append(round(result, 5))\n",
    "    weights.append(weight)\n",
    "print('[', end='')\n",
    "for index, weight in enumerate(weights):\n",
    "    print(f'{weight:.5f}, ', sep='', end='')\n",
    "print(']', end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values = counts\n",
    "min_value = min(values)\n",
    "max_value = max(values)\n",
    "# Calculate the range of the values\n",
    "value_range = max_value - min_value\n",
    "# Normalize the values and store them in a new list\n",
    "normalized_values = []\n",
    "for value in values:\n",
    "    normalized_value = ((value - min_value) / value_range) * 100\n",
    "    normalized_value = int(normalized_value)\n",
    "    normalized_values.append(normalized_value)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
